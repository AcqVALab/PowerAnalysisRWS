---
title: "Introduction to Power Analysis with R - AcqVA Aurora workshop"
author: "Martin Schweinberger"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  bookdown::html_document2: 
bibliography: bibliography.bib
link-citations: yes
---


```{r uq1, echo=F, fig.cap="", message=FALSE, warning=FALSE, out.width='100%'}
knitr::include_graphics("https://slcladal.github.io/images/acqvalab.png")
```


# Introduction{-}

This tutorial introduces power analysis for determining sample size using R with the aim of informing about the theoretical underpinnings, showcasing how to perform power analysis, and enabling participants on how to adapt, change, and modify data sets so that they can be fed into a power analysis using the `simr` [@simr]. 

```{r diff, echo=FALSE, out.width= "15%", out.extra='style="float:right; padding:10px"'}
knitr::include_graphics("https://slcladal.github.io/images/gyr_chili.jpg")
```

This tutorial is aimed at intermediate users of R. The aim is not to provide a fully-fledged guide but rather to show and exemplify how to perform a power analysis for a generalized linear mixed-effects modelas this is the most common type of analysis for experimental studies.


<div class="warning" style='padding:0.1em; background-color:#f2f2f2; color:#51247a'>
<span>
<p style='margin-top:1em; text-align:center'>
The entire R Notebook for the tutorial can be downloaded [**here**](https://github.com/MartinSchweinberger/AcqVA_PowerR_WS/acqvapwrws.Rmd).  If you want to render the R Notebook on your machine, i.e. knitting the document to html or a pdf, you need to make sure that you have R and RStudio installed and you also need to download the [**bibliography file**](https://github.com/MartinSchweinberger/AcqVA_DataVisR_WS/bibliography.bib) and store it in the same folder where you store the Rproj file. <br><br>
**[Here](https://colab.research.google.com/drive/1Ty2jK_JZo9hANAWXg-d_PRV8dKVx4P51?usp=sharing)** is a **link to an interactive version of this tutorial on Google Colab**. The interactive tutorial is based on a Jupyter notebook of this tutorial. This interactive Jupyter notebook allows you to execute code yourself and - if you copy the Jupyter notebook - you can also change and edit the notebook, e.g. you can change code and upload your own data.<br></p>
<p style='margin-left:1em;'>
</p></span>
</div>

<br>



## What to do before the workshop{-}

To get the most out of this workshop, you will need to have some (basic) R skills and (basic) knowledge of how to work with R, RStudio, R Projects, and R Notebooks. If you have no or little experience with this or if you need to refresh your skills, please carefully read (or optimally go through) these tutorials:

* [Getting started with R](https://slcladal.github.io/intror.html)

* [Handling tables in R](https://slcladal.github.io/table.html)

Before attending the workshop, you need to install the following packages in RStudio:

* `here` (for easy pathing)

* `tidyverse` (for data processing)

* `pwr` (for simple power analyses)

* `lme4` (for mixed-models)

* `sjPlot` (for summaries of mixed-models)

* `report` (for reporting mixed-models)

* `simr` (for power analyses for glmms)

* `knitr` (for knitting R Notebooks)

* `markdown` (for rendering Rmd files)

* `rmarkdown`  (for R Markdown formatting)

* `installr` (for updating R)


You can update R and install these packages by clicking on `packages` on the top of the lower right pane in RStudio or you can execute the following code in the lower left, `Console` pane of RStudio. 

```{r install, eval = F, message=F, warning=F}
# update R
#install.packages("installr")
#library(installr)
#updateR()
# install required packages
install.packages(c("tidyverse", "here",  "pwr", "lme4", "sjPlot", "report", "simr", "DescTools"), 
                 dependencies = T)
```


**It is really important that you have knowledge of R and RStudio and that you have installed the packages before the workshop so that we do not have to deal with technical issues too much.**

You can find a more detailed version of the content of this workshop in these two LADAL tutorials

* [Power Analysis with R](https://slcladal.github.io/pwr.html)

You can follow this workshop in different ways - you can sit back and watch it like a lecture or take a more active role - that said, the intention for this workshop is clearly to be practical so that I show something and then you do it on you computer and we have exercises where you can try out what you have just learned.

So, in essence, there are the following three options for following this workshop:

1. You can sit back and enjoy and focus on what you see and then go back home and try it by yourself later.

2. You can follow this workshop in RStudio and execute code, see what it does, understand it, and adapt it. This requires some skills in R and RStudio - although I have trued to keep things simple.

3. You can click on [this link]() which takes you to a Jupyter Notebook on Google Colab (and you are then ready to go - you only  have to install the packages which takes a couple of minutes). You can then copy that Notebook and save it in your own Google Drive and then execute code, modify it, and understand it. This does require less skills and will be easier for people who just want to focus on the code that produces certain visualizations without doing it in RStudio. Also, this get rid of most technical issues (hopefully) but the installation of packages will take a while and you will need to re-install the packages every time you want to re-use the Jupyter Notebook.

Choose which option suits you best and then go with it. 

## Timeline{-}

Here is what we have planned to cover in this workshop:

Tuesday, January 25, 10-12am

* Introduction

* Primer

* Session preparation

* How to load different data formats into R

* Theoretical underpinning

* Basics of data preparation 

* Getting started with pwr

* Generating, summarizing, and reporting some models

Tuesday, January 25, 1-3pm

* Getting started with simr

* Simulating data

* Simulating models

* Application of power analyses for mixed-effect models 

* Wrap-up and Resources



# Getting started{-}

If you choose option 2, you need to set up our R session and prepare our R project at the very beginning of the workshop. 

For everything to work, please do the following:

* Create a folder for this workshop somewhere on your computer, e.g. called *AcqVA_DataVisR_WS*

* In that folder, create two subfolders called *data* and *images*

* Open RStudio, go to File > New Project > Existing Directory (Browse to project folder) > Create (and hit Enter)

This will then create an R Project in the project folder.


## Theoretical underpinning{-}


What is power and why do we need power analyses?

Let's have a look at some distributions to understand what is going on...

## Effect size{-}

And let's start with varying effect size.


```{r same, echo = F, warning=F, message=F}
options(scipen = 999)
library(tidyverse)
library(DescTools)
set.seed(1234)
data.frame(time = c(rnorm(30,100,10), rnorm(30,100,10))) %>%
  dplyr::mutate(group = c(rep("Norwegian", 30), rep("English", 30))) %>%
  dplyr::mutate(group = factor(group)) %>%
  group_by(group) %>%
  mutate(mean = mean(time),
         cil = DescTools::MeanCI(time, conf.level=0.95)[2],
         ciu = DescTools::MeanCI(time, conf.level=0.95)[3]) %>%
  ungroup() %>%
  mutate(t = t.test(time ~ group, conf.level=0.95)[1],
         df = t.test(time ~ group, conf.level=0.95)[2],
         p = t.test(time ~ group, conf.level=0.95)[3]) %>%
  rowwise() %>%
  mutate(ttest = paste0("t: ", round(t, 2), ", df: ", round(df, 1), ", p-value: ", round(p, 4))) %>%
  select(-t, -df, -p)  -> pdat
ggplot(pdat, aes(x = time, group = group, color = group, linetype = group)) +
  geom_density(aes(alpha = .9)) +
  theme(legend.position = "none") +
  geom_vline(aes(xintercept = mean, color = group, linetype = group)) +
  geom_point(aes(x = mean, y = 0.05, group= group)) +  
  geom_errorbarh(aes(xmin = cil, xmax = ciu, y = 0.05, height = .005)) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(65, 135), ylim = c(0, 0.06)) +
  ggplot2::annotate("text", x = 120, y = 0.05, label = unique(pdat$ttest)) +
  labs(title = "2 groups (N = 30) sampled from the same population (with means and CIs)\n
       no effect (mean = 100, sd = 10)!",
       x = "", y = "Probability")
```

Now, lets have a look at at the distribution of two different groups (group has a weak effect, Cohen's *d* = .2)

```{r weak, echo = F, warning=F, message=F}
set.seed(123)
data.frame(time = c(rnorm(30,101,10), rnorm(30,99,10))) %>%
  dplyr::mutate(group = c(rep("Norwegian", 30), rep("English", 30))) %>%
  dplyr::mutate(group = factor(group)) %>%
  group_by(group) %>%
  mutate(mean = mean(time),
         cil = DescTools::MeanCI(time, conf.level=0.95)[2],
         ciu = DescTools::MeanCI(time, conf.level=0.95)[3]) %>%
  ungroup() %>%
  mutate(t = t.test(time ~ group, conf.level=0.95)[1],
         df = t.test(time ~ group, conf.level=0.95)[2],
         p = t.test(time ~ group, conf.level=0.95)[3]) %>%
  rowwise() %>%
  mutate(ttest = paste0("t: ", round(t, 2), ", df: ", round(df, 1), ", p-value: ", round(p, 4))) %>%
  select(-t, -df, -p)  -> pdat
ggplot(pdat, aes(x = time, group = group, color = group, linetype = group)) +
  geom_density(aes(alpha = .9)) +
  theme(legend.position = "none") +
  geom_vline(aes(xintercept = mean, color = group, linetype = group)) +
  geom_point(aes(x = mean, y = 0.05, group= group)) +  
  geom_errorbarh(aes(xmin = cil, xmax = ciu, y = 0.05, height = .005)) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(65, 135), ylim = c(0, 0.06)) +
  ggplot2::annotate("text", x = 120, y = 0.05, label = unique(pdat$ttest)) +
  labs(title = "2 groups (N = 30) sampled from *different* population (with means and CIs):
       weak effect in population (mean = 99; 101, sd = 10, d = .2)",
       x = "", y = "Probability")
```

Now, lets have a look at at the distribution of two different groups (group has a medium effect, Cohen's *d* = .5)

```{r medium, echo = F, warning=F, message=F}
set.seed(123)
data.frame(time = c(rnorm(30,102.5,10), rnorm(30,97.5,10))) %>%
  dplyr::mutate(group = c(rep("Norwegian", 30), rep("English", 30))) %>%
  dplyr::mutate(group = factor(group)) %>%
  group_by(group) %>%
  mutate(mean = mean(time),
         cil = DescTools::MeanCI(time, conf.level=0.95)[2],
         ciu = DescTools::MeanCI(time, conf.level=0.95)[3]) %>%
  ungroup() %>%
  mutate(t = t.test(time ~ group, conf.level=0.95)[1],
         df = t.test(time ~ group, conf.level=0.95)[2],
         p = t.test(time ~ group, conf.level=0.95)[3]) %>%
  rowwise() %>%
  mutate(ttest = paste0("t: ", round(t, 2), ", df: ", round(df, 1), ", p-value: ", round(p, 4))) %>%
  select(-t, -df, -p)  -> pdat
ggplot(pdat, aes(x = time, group = group, color = group, linetype = group)) +
  geom_density(aes(alpha = .9)) +
  theme(legend.position = "none") +
  geom_vline(aes(xintercept = mean, color = group, linetype = group)) +
  geom_point(aes(x = mean, y = 0.05, group= group)) +  
  geom_errorbarh(aes(xmin = cil, xmax = ciu, y = 0.05, height = .005)) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(65, 135), ylim = c(0, 0.06)) +
  ggplot2::annotate("text", x = 120, y = 0.05, label = unique(pdat$ttest)) +
  labs(title = "2 groups (N = 30) sampled from *different* population (with means and CIs):
       weak effect in population (mean = 97.5; 102.5, sd = 10, d = .5)",
       x = "", y = "Probability")
```

Now, lets have a look at at the distribution of two different groups (group has a strong effect, Cohen's *d* = .8)

```{r strong, echo = F, warning=F, message=F}
set.seed(123)
data.frame(time = c(rnorm(30,104,10), rnorm(30,96,10))) %>%
  dplyr::mutate(group = c(rep("Norwegian", 30), rep("English", 30))) %>%
  dplyr::mutate(group = factor(group)) %>%
  group_by(group) %>%
  mutate(mean = mean(time),
         cil = DescTools::MeanCI(time, conf.level=0.95)[2],
         ciu = DescTools::MeanCI(time, conf.level=0.95)[3]) %>%
  ungroup() %>%
  mutate(t = t.test(time ~ group, conf.level=0.95)[1],
         df = t.test(time ~ group, conf.level=0.95)[2],
         p = t.test(time ~ group, conf.level=0.95)[3]) %>%
  rowwise() %>%
  mutate(ttest = paste0("t: ", round(t, 2), ", df: ", round(df, 1), ", p-value: ", round(p, 4))) %>%
  select(-t, -df, -p)  -> pdat
ggplot(pdat, aes(x = time, group = group, color = group, linetype = group)) +
  geom_density(aes(alpha = .9)) +
  theme(legend.position = "none") +
  geom_vline(aes(xintercept = mean, color = group, linetype = group)) +
  geom_point(aes(x = mean, y = 0.05, group= group)) +  
  geom_errorbarh(aes(xmin = cil, xmax = ciu, y = 0.05, height = .005)) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(65, 135), ylim = c(0, 0.06)) +
  ggplot2::annotate("text", x = 120, y = 0.05, label = unique(pdat$ttest)) +
  labs(title = "2 groups (N = 30) sampled from *different* population (with means and CIs):
       weak effect in population (mean = 96; 104, sd = 10, d = .8)",
       x = "", y = "Probability")
```


Now, lets have a look at at the distribution of two different groups (group has a very strong effect, Cohen's *d* = 1.2)

```{r vstrong, echo = F, warning=F, message=F}
set.seed(123)
data.frame(time = c(rnorm(30,106,10), rnorm(30,94,10))) %>%
  dplyr::mutate(group = c(rep("Norwegian", 30), rep("English", 30))) %>%
  dplyr::mutate(group = factor(group)) %>%
  group_by(group) %>%
  mutate(mean = mean(time),
         cil = DescTools::MeanCI(time, conf.level=0.95)[2],
         ciu = DescTools::MeanCI(time, conf.level=0.95)[3]) %>%
  ungroup() %>%
  mutate(t = t.test(time ~ group, conf.level=0.95)[1],
         df = t.test(time ~ group, conf.level=0.95)[2],
         p = t.test(time ~ group, conf.level=0.95)[3]) %>%
  rowwise() %>%
  mutate(ttest = paste0("t: ", round(t, 2), ", df: ", round(df, 1), ", p-value: ", round(p, 4))) %>%
  select(-t, -df, -p)  -> pdat
ggplot(pdat, aes(x = time, group = group, color = group, linetype = group)) +
  geom_density(aes(alpha = .9)) +
  theme(legend.position = "none") +
  geom_vline(aes(xintercept = mean, color = group, linetype = group)) +
  geom_point(aes(x = mean, y = 0.05, group= group)) +  
  geom_errorbarh(aes(xmin = cil, xmax = ciu, y = 0.05, height = .005)) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(65, 135), ylim = c(0, 0.06)) +
  ggplot2::annotate("text", x = 120, y = 0.05, label = unique(pdat$ttest)) +
  labs(title = "2 groups (N = 30) sampled from *different* population (with means and CIs):
       weak effect in population (mean = 94; 106, sd = 10, d = 1.2)",
       x = "", y = "Probability")
```

**If variability and sample size remain constant, larger effects are easier to detect than smaller effects!**

## Sample size{-}

And let's now look at sample size.


```{r n30, echo = F, warning=F, message=F}
set.seed(1234)
data.frame(time = c(rnorm(30,97.5,10), rnorm(30,102.5,10))) %>%
  dplyr::mutate(group = c(rep("Norwegian", 30), rep("English", 30))) %>%
  dplyr::mutate(group = factor(group)) %>%
  group_by(group) %>%
  mutate(mean = mean(time),
         cil = DescTools::MeanCI(time, conf.level=0.95)[2],
         ciu = DescTools::MeanCI(time, conf.level=0.95)[3]) %>%
  ungroup() %>%
  mutate(t = t.test(time ~ group, conf.level=0.95)[1],
         df = t.test(time ~ group, conf.level=0.95)[2],
         p = t.test(time ~ group, conf.level=0.95)[3]) %>%
  rowwise() %>%
  mutate(ttest = paste0("t: ", round(t, 2), ", df: ", round(df, 1), ", p-value: ", round(p, 4))) %>%
  select(-t, -df, -p)  -> pdat
ggplot(pdat, aes(x = time, group = group, color = group, linetype = group)) +
  geom_density(aes(alpha = .9)) +
  theme(legend.position = "none") +
  geom_vline(aes(xintercept = mean, color = group, linetype = group)) +
  geom_point(aes(x = mean, y = 0.05, group= group)) +  
  geom_errorbarh(aes(xmin = cil, xmax = ciu, y = 0.05, height = .005)) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(65, 135), ylim = c(0, 0.06)) +
  ggplot2::annotate("text", x = 120, y = 0.05, label = unique(pdat$ttest)) +
  labs(title = "2 groups (N = 30) sampled from *different* population (with means and CIs):
       medium effect in population (mean = 97.5; 102.5, sd = 10, d = .5)",
       x = "", y = "Probability")
```


N = 50.


```{r n50, echo = F, warning=F, message=F}
set.seed(1234)
data.frame(time = c(rnorm(50,97.5,10), rnorm(50,102.5,10))) %>%
  dplyr::mutate(group = c(rep("Norwegian", 50), rep("English", 50))) %>%
  dplyr::mutate(group = factor(group)) %>%
  group_by(group) %>%
  mutate(mean = mean(time),
         cil = DescTools::MeanCI(time, conf.level=0.95)[2],
         ciu = DescTools::MeanCI(time, conf.level=0.95)[3]) %>%
  ungroup() %>%
  mutate(t = t.test(time ~ group, conf.level=0.95)[1],
         df = t.test(time ~ group, conf.level=0.95)[2],
         p = t.test(time ~ group, conf.level=0.95)[3]) %>%
  rowwise() %>%
  mutate(ttest = paste0("t: ", round(t, 2), ", df: ", round(df, 1), ", p-value: ", round(p, 4))) %>%
  select(-t, -df, -p)  -> pdat
ggplot(pdat, aes(x = time, group = group, color = group, linetype = group)) +
  geom_density(aes(alpha = .9)) +
  theme(legend.position = "none") +
  geom_vline(aes(xintercept = mean, color = group, linetype = group)) +
  geom_point(aes(x = mean, y = 0.05, group= group)) +  
  geom_errorbarh(aes(xmin = cil, xmax = ciu, y = 0.05, height = .005)) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(65, 135), ylim = c(0, 0.06)) +
  ggplot2::annotate("text", x = 120, y = 0.05, label = unique(pdat$ttest)) +
  labs(title = "2 groups (N = 50) sampled from *different* population (with means and CIs):
       medium effect in population (mean = 97.5; 102.5, sd = 10, d = .5)",
       x = "", y = "Probability")
```

**If variability and effect size remain constant, effects are easier to detect with increasing sample size!**

## Variability{-}

And let's now look at variability.


```{r sd10, echo = F, warning=F, message=F}
set.seed(1234)
data.frame(time = c(rnorm(30, 97.5, 10), rnorm(30, 102.5, 10))) %>%
  dplyr::mutate(group = c(rep("Norwegian", 30), rep("English", 30))) %>%
  dplyr::mutate(group = factor(group)) %>%
  group_by(group) %>%
  mutate(mean = mean(time),
         cil = DescTools::MeanCI(time, conf.level=0.95)[2],
         ciu = DescTools::MeanCI(time, conf.level=0.95)[3]) %>%
  ungroup() %>%
  mutate(t = t.test(time ~ group, conf.level=0.95)[1],
         df = t.test(time ~ group, conf.level=0.95)[2],
         p = t.test(time ~ group, conf.level=0.95)[3]) %>%
  rowwise() %>%
  mutate(ttest = paste0("t: ", round(t, 2), ", df: ", round(df, 1), ", p-value: ", round(p, 4))) %>%
  select(-t, -df, -p)  -> pdat
ggplot(pdat, aes(x = time, group = group, color = group, linetype = group)) +
  geom_density(aes(alpha = .9)) +
  theme(legend.position = "none") +
  geom_vline(aes(xintercept = mean, color = group, linetype = group)) +
  geom_point(aes(x = mean, y = 0.05, group= group)) +  
  geom_errorbarh(aes(xmin = cil, xmax = ciu, y = 0.05, height = .005)) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(50, 150), ylim = c(0, 0.06)) +
  ggplot2::annotate("text", x = 120, y = 0.05, label = unique(pdat$ttest)) +
  labs(title = "2 groups (N = 30) sampled from *different* population (with means and CIs):
       medium effect in population (mean = 97.5; 102.5, sd = 10, d = .5)",
       x = "", y = "Probability")
```
Let's decrease the variability to sd = 5.

```{r sd5, echo = F, warning=F, message=F}
set.seed(1234)
data.frame(time = c(rnorm(30, 97.5, 5), rnorm(30, 102.5, 5))) %>%
  dplyr::mutate(group = c(rep("Norwegian", 30), rep("English", 30))) %>%
  dplyr::mutate(group = factor(group)) %>%
  group_by(group) %>%
  mutate(mean = mean(time),
         cil = DescTools::MeanCI(time, conf.level=0.95)[2],
         ciu = DescTools::MeanCI(time, conf.level=0.95)[3]) %>%
  ungroup() %>%
  mutate(t = t.test(time ~ group, conf.level=0.95)[1],
         df = t.test(time ~ group, conf.level=0.95)[2],
         p = t.test(time ~ group, conf.level=0.95)[3]) %>%
  rowwise() %>%
  mutate(ttest = paste0("t: ", round(t, 2), ", df: ", round(df, 1), ", p-value: ", round(p, 4))) %>%
  select(-t, -df, -p)  -> pdat
ggplot(pdat, aes(x = time, group = group, color = group, linetype = group)) +
  geom_density(aes(alpha = .9)) +
  theme(legend.position = "none") +
  geom_vline(aes(xintercept = mean, color = group, linetype = group)) +
  geom_point(aes(x = mean, y = 0.125, group= group)) +  
  geom_errorbarh(aes(xmin = cil, xmax = ciu, y = 0.125, height = .005)) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(50, 150), ylim = c(0, 0.15)) +
  ggplot2::annotate("text", x = 120, y = 0.125, label = unique(pdat$ttest)) +
  labs(title = "2 groups (N = 30) sampled from *different* population (with means and CIs):
       medium effect in population (mean = 97.5; 102.5, sd = 5, d = .5)",
       x = "", y = "Probability")
```

**If the sample and effect size remain constant, effects are easier to detect with decreasing variability!**

<div class="warning" style='padding:0.1em; background-color:#f2f2f2; color:#51247a'>
<span>
<p style='margin-top:1em; text-align:center'>
What power analysis allow us to do is to calculate at what sample size we would be able to detect an effect of a certain strength with a predefined certainty, given a certain amount of variability. <br><br>In other words, assuming the variability in the pilot data is the same as in the population, how many subjects do we need to detect a weak (or median or strong) effect with 80 percent certainty?<br></p>
<p style='margin-left:1em;'>
</p></span>
</div>

<br>

# Today's Data{-}


We will use 3 data sets, two data sets that Yulia provided and one that was send in by Isabel. The publications associated with the data are:

The Accent data (already published): 

Kupisch, Tanja, Nadine Kolb, Yulia Rodina, and Olga Urek. 2021. Foreign Accent in Pre- and Primary School Heritage Bilinguals. *Languages* 6(2), 96; https://doi.org/10.3390/languages6020096

And the L2 English intervention data (which is still in progress):

Nygaard, Maren, Chistopher Loe Olsen, and Yulia Rodina. In progress. The effect of form-focused intervention on subject-verb agreement in L1 Norwegian L2 English learners.

In addition, we will use a data set that is part of the `likert` package and a data set that Isabel provided for the mixed-model effects visualization.

Here are summaries of the data sets:

1. **`AJT_V2`** (we will call this data `regdata`: contains 2103 observations of the following 14 variables:
  + ID: n = 2103 (0% missing)
  + Version: n = 2103 (Mean = 11.53, SD = 5.44)
  + Task.Name: 1 level, namely *AJT*
  + Response: 2 levels, namely Bad (n = 841, 39.99%) and Good (n = 1262, 60.01%)
  + Response_num: n = 2103 (Mean = 0.60, SD = 0.49)
  + Sentence: 24 levels
  + Group: 2 levels, namely *English* (n = 1193) and *Norwegian-English* (n = 910)
  + Word_order: 2 levels, namely *V2* (n = 1054) and *V3* (n = 1049)
  + Num: n = 2103 (Mean = 8.41, SD = 5.2)
  + Sentence_type: 2 levels, namely *Non-subject-initial* (n = 1053) and *Sentence adverbials* (n = 1050)
  + Gender: 2 levels, namely *Female* (n = 1601) and *Male* (n = 502)
  + Age: n = 2103 (Mean = 32.43, SD = 12.07)
  + Acc: n = 2103 (Mean = 0.23, SD = 0.42)
  + Condition: 4 levels, namely *AdverbV2* (n = 528), *AdverbV3* (n = 525), *TopV2* (n = 526) and *TopV3* (n = 524)

# Basic Power Analysis{-}


The basis for the present tutorial is @green2016simr (which you can find [here](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12504)). @green2016simr is a highly recommendable and thorough tutorial on performing power analysis in R. Recommendable literature on this topic are, e.g. @arnold2011simulation and @johnson2015power and [this tutorial](https://www.journalofcognition.org/articles/10.5334/joc.10/). 

<div class="warning" style='padding:0.1em; background-color:#f2f2f2; color:#51247a'>
<span>
<p style='margin-top:1em; text-align:center'>
<b>NOTE</b><br>Power analysis have also been used post-hoc to test if the sample size of studies was sufficient to detect meaningful effects. However, such post-hoc power calculations where the target effect size comes from the data, give misleading results [@hoenig2001abuse; @perugini2018practical] and should thus be treated with extreme care!</p>
<p style='margin-left:1em;'>
</p></span>
</div>

<br>



## What determines if you find an effect?{-}

There are different factors that determine if a model finds an effect. The accuracy (i.e., the probability of finding an effect) depends on three main factors:

* the size of the effect (bigger effects are easier to detect)
* the variability of the effect (less variability makes it easier to detect an effect), and 
* the sample size (the bigger the sample size, the easier it is to detect an effect); 
  + number of subjects/participants
  + number of items/questions
  + number of observations per item within subjects/participants
  
Now, if a) we dealing with a very big effect, then we need only few participants and few items to accurately find this effect.

Or b) if we dealing with an effect that has low variability (it is observable for all subjects with the same strength), then we need only few participants and few items to accurately find this effect.

Before we conduct a study, we should figure out, what sample we need to detect a small/medium effect with medium variability so that our model is sufficient to detect this kind of effect. In order to do this, we would generate a data set that mirrors the kind of data that we expect to get (with the properties that we expect to get). We can then fit a model to this data and check if a model would be able to detect the expected effect. However, because a single model does not tell us that much (ift could simply be luck that it happened to find the effect), we run many different models on variations of the data and see how many of them find the effect. As a general rule of thumb, we want a data set that allows a model to find a medium sized effect with at least an accuracy of 80 percent [@field2007making].

In the following, we will go through how to determine what sample size we need for an example analysis.


## Preparation and session set up{-}

This tutorial is based on R. If you have not installed R or are new to it, you will find an introduction to and more information how to use R [here](https://slcladal.github.io/intror.html). For this tutorials, we need to install certain *packages* into the R *library* on your computer so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead and ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time).

```{r prep1, echo=T, eval = F, message=FALSE, warning=FALSE}
# install libraries
install.packages(c("tidyverse", "lme4", "sjPlot", "simr"))
install.packages(c("DT", "knitr", "flextable"))
```

Now that we have installed the packages, we can activate them as shown below.

```{r prep2, message=FALSE} 
# set options
options(stringsAsFactors = F)         # no automatic conversion of factors
options("scipen" = 100, "digits" = 4) # suppress math annotation
options(max.print=1000)               # print max 1000 results
# load packages
library(tidyverse)
library(lme4)
library(sjPlot)
library(simr)
library(DT)
library(knitr)
library(flextable)
```

Once you have installed R and RStudio and initiated the session by executing the code shown above, you are good to go.

## Generating data{-}

In order to perform a  power analysis, we will start by loading the tidyverse package to process the data and by generating a data that we will use to determine the power of a regression model.

This simulated data set has

* 200 data points
* 2 Conditions (Control, Test)
* 10 Subjects
* 10 Items

```{r pwr1, message=F, warning=F}
# generate data
simdat <- data.frame(
  sub <- rep(paste0("Sub", 1:10), each = 20),
  cond <- rep(c(
    rep("Control", 10),
    rep("Test", 10))
    , 10),
  itm <- as.character(rep(1:10, 20))
) %>%
  dplyr::rename(Subject = 1,
                Condition = 2,
                Item = 3) %>%
  dplyr::mutate_if(is.character, factor)
```


```{r pwr1b, echo = F}
# inspect data
simdat %>%
  head(15) %>%
  kable(caption = "First 15 rows of simdat.") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                            full_width = F)
```

We add a dependent variable (AOI) which represents the dependent variable in the study. In our case, we determine that Condition has a relatively weak effect (the probability of gazing into the area of interest (AOI) is .7 in the test condition compared to .5 in the control condition). In addition, this effect is only present in half of the subjects to reflect the variability in the effect. 

```{r}
simdat <- simdat %>%
  dplyr::arrange(Condition) %>%
  dplyr::mutate(
  dep <- c(sample(c("AOI", "NotAOI"), 50, replace = T, prob = c(.5, .5)),
           sample(c("AOI", "NotAOI"), 50, replace = T, prob = c(.5, .5)),
           sample(c("AOI", "NotAOI"), 50, replace = T, prob = c(.5, .5)),
           sample(c("AOI", "NotAOI"), 50, replace = T, prob = c(.7, .3)))
  ) %>%
  dplyr::mutate_if(is.character, factor) %>%
  dplyr::rename(AOI = 4)
```


The data looks like this. 

```{r pwr3, echo = F}
DT::datatable(simdat, rownames = FALSE, filter="none", caption = "Overview of the data set.", 
              options = list(pageLength = 10, scrollX=T))
```


# Post-Hoc Power Analysis

Now that we have generated some data, we will fit a model to it and perform a power analysis on the observed effects. 

***

<div class="warning" style='padding:0.1em; background-color:#f2f2f2; color:#51247a'>
<span>
<p style='margin-top:1em; text-align:center'>
<b>NOTE</b><br>Post-hoc power calculations (where the target effect size comes from the data) give misleading results [@hoenig2001abuse; @perugini2018practical] and should thus be treated with extreme care!</p>
<p style='margin-left:1em;'>
</p></span>
</div>

***

We will fit a first model to the data. Thus, in a first step, we load the `lme4` package to create a model, set a seed (to save the results and so that the results can be replicated), and then create an initial mixed-effects model.

```{r pwr4, message=F, warning=F}
# set seed for replicability
set.seed(12345)
# fit model
m1 <- glmer(AOI ~ (1|Subject) +(1|Item) + Condition, family="binomial", data=simdat)
# inspect results
summary(m1)
```

We now check the effect sizes of the predictors in the model. We can do this by displaying the results of the model using the `tab_model` function from the `sjPlot` package.


```{r pwr5, message=F, warning=F}
# tabulate results
sjPlot::tab_model(m1)
```


Now, we perform power analysis on an observed effect. This analysis tells us how likely the model is to find an observed effect given the data.

***

<div class="warning" style='padding:0.1em; background-color:#f2f2f2; color:#51247a'>
<span>
<p style='margin-top:1em; text-align:center'>
<b>NOTE</b><br>We use a very low number of simulations (100) and we use the default z-test which is suboptimal for small samples [@bolker2009generalized]. In a proper study, you should increase the number of simulations (to at least 1000) and you should use a bootstrapping rather than a z-test [cf. @halekoh2014kenward].</p>
<p style='margin-left:1em;'>
</p></span>
</div>

***




```{r pwr7, results='hide', message = FALSE, warning=F}
# set seed for replicability
set.seed(12345)
# perform power analysis for present model
rsim0 <- powerSim(m1, fixed("ConditionTest", "z"), nsim=100)
```

Now we can inspect the results. 

```{r pwr8, message = FALSE, warning = FALSE}
# inspect results
rsim0
```


The results of the power analysis show that, given the data at hand, the model would have detected the effect of `Conidition:Test` with a probability of `r rsim0$x` percent. However, and as stated above, the results of such post-hoc power calculations (where the target effect size comes from the data) give misleading results [@hoenig2001abuse] and should thus be treated with extreme care!

# Power Analysis of Set Effects

While the effect of `Condidition:Test` is rather small (given the small number of subjects and items, the small effect size, and the variability in the effect and we would thus not be surprised that out model is not very accurate in detecting this effect), the target accuracy of finding an effect that one is interested in is commonly 80 percent [cf. @field2012discovering; @green2016simr]. The accuracy (i.e., the probability of finding an effect) depends on three main factors:


* the size of the effect (bigger effects are easier to detect)
* the variability of the effect (less variability makes it easier to detect an effect), and 
* the sample size (the bigger the sample size, the easier it is to detect an effect); 
  + number of subjects/participants
  + number of items/questions
  + number of observations per item within subjects/participants
  

We will now check if the sample size is sufficient to detect a small effect (Cohen's d 0.2). According to @chen2010big odds ratios of 1.68, 3.47, and 6.71 are equivalent to Cohen's d = 0.2 (small), 0.5 (medium), and 0.8 (large) - the traditional scale is 0.2 for a small, 0.5 for medium sized, and 0.8 for a large or strong effect [cf. also @perugini2018practical, 2]. We need to determine the odds ratios of the fixed effects and then convert them into Cohen's d values for which we have associations between traditional denominations (small, medium, and large) and effect size values. 


```{r pwr9, message=FALSE, warning=FALSE}
estimatesfixedeffects <- fixef(m1)
exp(estimatesfixedeffects)
```

We can see that the effect is rather small which makes it very hard to detect an effect. We will now change the size of the effect of ConditionTest to represent a truly *small* effect, i.e. on the brink of being noise but being just strong enough to be considered small. In other words, we will set the effect so that its odds ratio is exactly 1.68.  


```{r pwr10, message=FALSE, warning=FALSE}
# set seed for replicability
set.seed(12345)
# perform power analysis for small effect
fixef(m1)["ConditionTest"] <- 0.519
estimatesfixedeffects <- fixef(m1)
exp(estimatesfixedeffects)
```

Now we can test if the sample size of the model is sufficient to find a small effect. 

```{r pwr11, results='hide', message = FALSE, warning=F}
# set seed for replicability
set.seed(12345)
# perform power analysis for present model
rsim1 <- powerSim(m1, fixed("ConditionTest", "z"), nsim=100)
```

The results are shown below. 

```{r pwr12, message = FALSE, warning=F}
# show results
rsim1
```

The power analysis shows that the data is sufficient to detect a small effect for Condition:Test with `r rsim1$x` percent accuracy.

# Power Analysis of Extended Data

We will now extend the data to see what sample size is needed to get to the 80 percent accuracy threshold. We begin by increasing the number of items from 10 to 30 to see if this would lead to a sufficient sample size.


```{r pwr13, results='hide', message = FALSE, warning=F}
# increase sample size
m2 <- extend(m1, along="Item", n=30)
# perform power simulation
rsim2 <- powerSim(m2, fixed("ConditionTest", "z"), nsim=100)
```

The results are shown below. 

```{r pwr14, message = FALSE, warning=F}
# show results
rsim2
```

By increasing the number of items to 30, we would now be able to detect a small effect (d=.2) with an accuracy of `r rsim2$x` percent. This means that we would have to add more items as 30 is not yet sufficient.

# Power Analysis for Ranges

We can also check the accuracy for a range of values as shown below. We begin by extending the number of Items.

```{r pwr15, results='hide', message = FALSE, warning=F}
pc2 <- powerCurve(m2, fixed("ConditionTest", "z"), along = "Item", nsim=100)
```

The results are shown below. 

```{r pwr16, message = FALSE, warning=F}
# show results
print(pc2)
```

In addition, we can plot the results as follows:


```{r pwr17, message = FALSE, warning=F}
plot(pc2)
```

Instead of increasing the number of Items, we could also increase the number of Subjects. So below, we test check the accuracy for up to 30 subjects.

```{r pwr18, results='hide', message = FALSE, warning=F}
m3 <- extend(m1, along="Subject", n=30)
# perform power calculation
pc3 <- powerCurve(m3, fixed("ConditionTest", "z"), along="Subject", nsim=100)
```

The results are shown below. 

```{r pwr19, message = FALSE, warning=F}
# print results
print(pc3)
```

Again, we can also visualize the results.

```{r pwr20, warning = F, message = FALSE}
# visualize results
plot(pc3) 
```

The results show that we breach the 80 percent threshold with 30 subjects.

Finally, it may be an option to increase the number of data points within subjects and items (while the number of items and subjects remain constant). 

```{r pwr21, results='hide', message = FALSE, warning=F}
m4 <- extend(m1, within="Item+Subject", n=15)
# perform power calculation
pc4 <- powerCurve(m4, fixed("ConditionTest", "z"), within="Item+Subject", breaks=c(5, 10, 15), nsim=100)
```

The results are shown below. 

```{r pwr22, message = FALSE, warning=F}
# show results
print(pc4)
```

```{r pwr23, message = FALSE, warning=F}
# show results
plot(pc4)
```

The results show that we would have a sufficient data set if we had 14 observations per Subject in each Item because with 10 observations, the accuracy breaches the 80 percent level.


# Wrap-up and Resources{-}

If you want to know more, please have a look/go at the following resources:

* 

That's all folks!

# Citation & Session Info {-}

Schweinberger, Martin. `r format(Sys.time(), '%Y')`. *Introduction to Data Visualization with R - AcqVA Aurora workshop*. Tromsø: The Arctic University of Norway, Tromsø. url: https://slcladal.github.io/introviz.html  (Version `r format(Sys.time(), '%Y.%m.%d')`).

```
@manual{schweinberger`r format(Sys.time(), '%Y')`acqvavizrws,
  author = {Schweinberger, Martin},
  title = {Introduction to Data Visualization with R - AcqVA Aurora workshop},
  note = {https://slcladal.github.io/introviz.html},
  year = {`r format(Sys.time(), '%Y')`},
  organization = "The Arctic University of Norway (UiT), AcqVA Aurora Center},
  address = {Tromsø},
  edition = {`r format(Sys.time(), '%Y.%m.%d')`}
}
```


```{r fin}
sessionInfo()
```

***

[Back to top](#introduction)


***

# References {-}


